-- 线性回归
  - 使用线性回归的时候什么时候会需要用L2？
  - 线性回归的原理, 距离怎么求, 方程参数怎么出来的


-- LR (逻辑回归)
  - 手推LR 的损失函数，目标函数、梯度下降手推
  - LR 怎么加入非线性？
  - 推一下LR的损失函数以及梯度传递
  - LR 为什么用sigmoid函数？
  - LR介绍、LR对特征需要做什么特殊处理吗？类别特征、连续特征。
  - 逻辑回归的目标函数(损失函数)是凸函数吗？
  - 为什么逻辑回归要用交叉熵损失函数？
  - Lr和决策树做分类优缺点，和对比
  

-- SVM 
  - 手推 SVM
  - SVM 的目标函数， 其中的软间隔是什么意思？
  - SVM 为什么叫支持向量机、损失函数是什么、核函数，怎么解决的线性不可分问题？
  - SVM 为什么变成对偶问题来求解？
  - SVM 为什么能用拉格朗日乘子法将原始最优化问题转化为极大极小问题，数学原理是什么
  - SVM的KTT条件？说了说，说到SMO实在说不下去了。
  - 解释几何间隔和函数间隔
  - 什么是NP－hard问题
  

-- LR (逻辑回归) +  SVM
  - LR 为什么不用 MSE，SVM 为什么用hinge不用logloss
  - LR和SVM的区别（写出各自目标函数）

-- 决策树
  - 描述决策树，如何选特征，怎么划分，怎么剪枝，介绍信息增益
  - 决策树分支的原理
  - 各种决策树模型的优劣（ID3 C4.5 CART的区别）
  - 决策树怎么解决回归问题?
  - 决策树（讲了三种决策树及分支点选择策略:手写信息增益和基尼系数等）
  -决策树怎么分支，分支的点怎么算
  - 

-- GBDT（梯度下降树）+ XGBoost
  - GBDT 原理，推导
  - GBDT 中的CART回归树每个叶子节点的输出值是什么
  - 为什么随机森林的树比 GBDT 的深一点？
  - 介绍 GBDT与XGBoost的区别
  
  - boosting方法（先讲了总的boosting方法,然后讲了gbdt,手推其原理）
  
  - 手推  XGBoost
  - XGBoost 过拟合了，怎么调参数？
  - XGBoost，每个叶子节点的值是怎么确定的？
  - XGBoost 的默认深度
  - XGBoost 如何处理缺失数据？
  - lightgbm和xgboost区别
  - 介绍XGBoost对GBDT的提升，LightGBM对XGBoost的提升，以及既然使用了LGB为什么还要使用XGB
  - XGBoost 怎么解决过拟合？怎么剪枝？怎么选择特征？怎么处理缺失值？
  - XGBoost的损失函数是什么，节点划分准则是什么
  - XGBoost怎么调参？用了多少棵树？
  - 树的分裂方式（id3,gini,gdbt,xgboost）
  - GBDT和randomForest区别？原理角度，方差、偏差角度，过拟合角度

-- 介绍常见的集成方法
-- bagging vs boosting简述
-- 介绍随机森林和GBDT的区别 为什么Bagging降方差，Boosting降偏差？


-- Kmeans的缺点？如何改善？
-- 讲一下K-means算法的过程以及原理
-- K-Means 聚类这种方法一定会收敛嘛？如果不收敛，怎么办？
-- kmeans聚类算法， k-means中的k是怎么确定的？

- 朴素贝叶斯与贝叶斯有什么区别？
- 隐马尔科夫模型用途、什么原理
- 隐马尔可夫模型原理, 发射概率, 状态转移概率, 每层要记住所有路径吗


- 特征工程理解 、 归一化的理解。
- 向量相似度计算方法 、 欧氏距离非欧距离、向量召回加速方法、FAISS
- 现有两个特征向量，怎么分析他们的相似度？
- 有没有什么数学方法能够去除特征矩阵中的噪声？
- 为什么要对连续型数值进行离散化，这样做有什么优势？
- Bert里面位置向量的作用是什么？有哪些生成方式？
- 知道哪些降维的方法，具体讲讲


- 缺失值如何处理，什么情况下均值、众数，什么情况下丢弃特征。
- 诸如ID类的特征如何处理，编码方式one-hot还是其他的，高维时？什么样才算高维，有没有界定？
- 聚类的算法有哪些？评价方法？优化算法？
- 介绍一阶二阶边缘检测算子一阶二阶边缘检测算子

正则项的了解
凸优化了解吗？牛顿法、SGD、最小二乘法，各自的优势。
凸优化其他东西呢？
k-means聚类这种方法一定会收敛嘛？如果不收敛，你怎么办？

--- 概率论
- 已知x.y的概率分布，求max x,y的分布
- 数学题，已知a,b都服从均值为0，方差为1的正态分布，求max(a,b)的期望
- 数学题：抛一枚硬币，第一次出现正面的期望
- 数学题：抛一枚硬币，连续两次出现正面的期望
- 概率题：一件事件成功的概率是p，连续多次独立实验直到连续成功n次，求需要进行的实验次数期望。
- 智力题：一个小时平均闯红灯5次，问一个小时闯红灯6次的概率，这个就泊松分布。一家人两个孩子，已知一个是女儿，问两个都是女儿的概率，这个简单，条件概率而已
