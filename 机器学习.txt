-- 线性回归
  - 使用线性回归的时候什么时候会需要用L2？
  - 线性回归的原理, 距离怎么求, 方程参数怎么出来的

--梯度下降手推

-- LR (逻辑回归)
  - 手推LR 的损失函数，目标函数、
  - LR 怎么加入非线性？
  - 推一下LR的损失函数以及梯度传递
  - LR 为什么用sigmoid函数？（为了求出分类概率）为什么不采用其他函数（sigmoid函数对偏远值不敏感？）
  - LR介绍、LR对特征需要做什么特殊处理吗？类别特征、连续特征。
  - 逻辑回归的目标函数(损失函数)是凸函数吗？
  - LR逻辑回归为什么要用交叉熵损失函数？（因为引入sigmoid函数，如果使用MSE损失会使目标函数非凸，无法求解）
  - Lr和决策树做分类优缺点，和对比
  

-- SVM 
  - 手推 SVM
  - SVM 的目标函数， 其中的软间隔是什么意思？
  - SVM 为什么叫支持向量机、损失函数是什么、核函数，怎么解决的线性不可分问题？
  - SVM 为什么变成对偶问题来求解？
  - SVM 为什么能用拉格朗日乘子法将原始最优化问题转化为极大极小问题，数学原理是什么
  - SVM的KTT条件？说了说，说到SMO实在说不下去了。
  - 解释几何间隔和函数间隔
  - 什么是NP－hard问题
  - 样本不平衡对svm的影响（几乎没有）
  - 讲一下SMO算法
  - SVM 需不需要做 normalization
  - SVM的KTT条件？说了说，说到SMO实在说不下去了
  - SVM有哪些核函数？
  - SVM引入核函数本质？	
  

-- LR (逻辑回归) +  SVM
  - LR 为什么不用 MSE，SVM 为什么用hinge不用logloss
  - LR和SVM的区别（写出各自目标函数）

-- 决策树
  - 描述决策树，如何选特征，怎么划分，怎么剪枝，介绍信息增益
  - 决策树分支的原理
  - 各种决策树模型的优劣（ID3 C4.5 CART的区别）
  - 决策树怎么解决回归问题?
  - 决策树（讲了三种决策树及分支点选择策略:手写信息增益和基尼系数等）
  - 决策树怎么分支，分支的点怎么算
  - 信息增益 信息增益比 区别
  - 

-- GBDT（梯度下降树）+ XGBoost
  - GBDT 原理，推导
  - GBDT 中的CART回归树每个叶子节点的输出值是什么
  - 为什么随机森林的树比 GBDT 的深一点？
  - 介绍 GBDT与XGBoost的区别
  
  - boosting方法（先讲了总的boosting方法,然后讲了gbdt,手推其原理）
  
  - 手推  XGBoost
  - XGBoost 过拟合了，怎么调参数？
  - XGBoost，每个叶子节点的值是怎么确定的？
  - XGBoost 的默认深度
  - XGBoost 如何处理缺失数据？
  - lightgbm和xgboost区别
  - 介绍XGBoost对GBDT的提升，LightGBM对XGBoost的提升，以及既然使用了LGB为什么还要使用XGB
  - XGBoost 怎么解决过拟合？怎么剪枝？怎么选择特征？怎么处理缺失值？
  - XGBoost的损失函数是什么，节点划分准则是什么
  - XGBoost怎么调参？用了多少棵树？
  - 树的分裂方式（id3,gini,gdbt,xgboost）
  - GBDT和randomForest区别？原理角度，方差、偏差角度，过拟合角度

-- 介绍常见的集成方法
-- bagging vs boosting简述
-- 介绍随机森林和GBDT的区别 为什么Bagging降方差，Boosting降偏差？


-- Kmeans的缺点？如何改善？
-- 讲一下K-means算法的过程以及原理
-- K-Means 聚类这种方法一定会收敛嘛？如果不收敛，怎么办？
-- kmeans聚类算法， k-means中的k是怎么确定的？


- 假设两个分布A 和 B，我们一般怎么衡量两个分布之间的距离，一般用什么距离？
- 假设A和 B 服从(0,1)的均匀分布，并且A和B相互独立，求max(A, B)的数学期望。

- 朴素贝叶斯与贝叶斯有什么区别？
- 隐马尔科夫模型用途、什么原理
- 隐马尔可夫模型原理, 发射概率, 状态转移概率, 每层要记住所有路径吗


- 特征工程理解 、 归一化的理解。
- 向量相似度计算方法 、 欧氏距离非欧距离、向量召回加速方法、FAISS
- 现有两个特征向量，怎么分析他们的相似度？
- 有没有什么数学方法能够去除特征矩阵中的噪声？
- 为什么要对连续型数值进行离散化，这样做有什么优势？
- Bert里面位置向量的作用是什么？有哪些生成方式？
- 知道哪些降维的方法，具体讲讲


- 缺失值如何处理，什么情况下均值、众数，什么情况下丢弃特征。
- 诸如ID类的特征如何处理，编码方式one-hot还是其他的，高维时？什么样才算高维，有没有界定？
- 聚类的算法有哪些？评价方法？优化算法？
- 介绍一阶二阶边缘检测算子一阶二阶边缘检测算子

正则项的了解
凸优化了解吗？牛顿法、SGD、最小二乘法，各自的优势。
凸优化其他东西呢？
k-means聚类这种方法一定会收敛嘛？如果不收敛，你怎么办？




微信---2020/7/9 
机器学习理论类：

1.  写出全概率公式&贝叶斯公式
2.  模型训练为什么要引入偏差(bias)和方差(variance)？  证
3.  CRF/朴素贝叶斯/EM/最大熵模型/马尔科夫随机场/混合高斯模型
4.  如何解决过拟合问题？
5.  One-hot的作用是什么？为什么不直接使用数字作为表示
6.  决策树和随机森林的区别是什么？
7.  朴素贝叶斯为什么“朴素naive”？
8.  kmeans初始点除了随机选取之外的方法
9.  LR明明是分类模型为什么叫回归
10. 梯度下降如何并行化
11. LR中的L1/L2正则项是啥
12. 简述决策树构建过程
13. 解释Gini系数
14. 决策树的优缺点
15. 出现估计概率值为 0 怎么处理
16. 随机森林的生成过程
17. 介绍一下Boosting的思想
18. gbdt的中的tree是什么tree？有什么特征
19. xgboost对比gbdt/boosting Tree有了哪些方向上的优化
20. 什么叫最优超平面
21. 什么是支持向量
22. SVM如何解决多分类问题
23. 核函数的作用是啥



特征工程类：

1.  怎么去除DataFrame里的缺失值？
2.  特征无量纲化的常见操作方法
3.  如何对类别变量进行独热编码？
4.  如何把“年龄”字段按照我们的阈值分段？
5.  如何根据变量相关性画出热力图？
6.  如何把分布修正为类正态分布？
7.  怎么简单使用PCA来划分数据且可视化呢？
8.  怎么简单使用LDA来划分数据且可视化呢？












------概率题------

-- 求圆上任意三个点组成一个三角形是锐角三角形的概率。
-- 概率：圆上任意三个点组成的三角形，包含圆心的概率
-- 一根木棒截成三段，问能组成三角形的概率

--- 概率论
- 数学题，已知a,b都服从均值为0，方差为1的正态分布，求max(a,b)的期望
- 数学题：抛一枚硬币，第一次出现正面的期望
- 数学题：抛一枚硬币，连续两次出现正面的期望
- 概率题：一件事件成功的概率是p，连续多次独立实验直到连续成功n次，求需要进行的实验次数期望。
- 智力题：一个小时平均闯红灯5次，问一个小时闯红灯6次的概率，这个就泊松分布。一家人两个孩子，已知一个是女儿，问两个都是女儿的概率，这个简单，条件概率而已
- 已知x，y的期望和方差，且x，y独立，求xy的方差
- 已知x，y独立同分布，求max(x,y)的期望
- 已知A、B两个人在一个圆里放硬币，谁放不下谁输，已知A先放，求有没有A必赢的策略
- 第一问，掷三个骰子，掷出来的三个值之和为10的概率。我用的笨方法，列举出所有情况算概率。
- 第二问，掷四个骰子，掷出来的四值之和概率最大的是哪一个。猜的14，猜对了。
- 第三问，第二问中的掷出来是14的概率有多大。没有任何思路，后来面试官告诉我可以用动态规划来做（很诧异，不是数学题吗），在面试官的提示下，写了动态转移方程。
- 一个硬币，正面向上是p，投2k+1次，正面比反面多的概率，写出表达式
- 一个商店，1个小时卖出去5个包子，问下一个小时卖出6个的概率
- 一个家庭有两个孩子，已知有一个是女孩子，问全是女孩子的概率是多少
- 甲获胜的概率0.6，乙获胜的概率0.4，问甲应该选2/3，还是3/5
- 抛一个硬币2000次，问一般向上的概率
- 概率1: 11个球，1个特殊球，两个人无放回拿球，问第一个人取到特殊球的概率
- 概率2: 11个球，1个特殊球，两个人有放回拿球，问先拿到这个特殊球的概率
- 三个碗只有一个有球，你选定一个后我拿走一个没有球的碗，你要不要更换你选定的碗？
- 代码题：
（1）n个骰子的同时放下，上面朝上的点数总和为s的概率是多少？
（2）给一个数组和滑动窗口大小，求滑动窗口内的最大值是多少？
- 概率题：2个盒子，50个红球和50个白球，怎么放使得摸到红球概率最大（计算步骤）
- 总共有三个箱子，一个箱子装2个红球，一个箱子装2个篮球，一个箱子装1红球1篮球，在第一次摸到红球的前提下，在此箱子中再次摸到红球的概率（贝叶斯）
- 来自jpm，一维数轴上，从0出发，p的概率向左，1-p的概率向右。n步以后，这个点到达最右减最左的期望。
- 问题：两个独立变量满足0到1均匀分布，求两个变量最大值的期望。