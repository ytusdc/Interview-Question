
#面试经验# 京东/拼多多/BIGO/陌陌/苏宁/浦发
方向：ML/DL/CV/NLP
- 决策树怎么解决回归问题?
- XGBoost 过拟合了，怎么调参数？
- 直方图均衡化知道吗？说下算法思路？
- asoftmax和arcface的损失是怎样的？
- lstm和RNN对于哪些问题题更擅长？
- 从2w条样本中采样2000条点赞数最高的怎么做？
- pytorch中多卡训练的过程是怎样的？说下gather scatter是怎么做的？
- 三个碗只有一个有球，你选定一个后我拿走一个没有球的碗，你要不要更换你选定的碗？
- 代码题：
（1）n个骰子的同时放下，上面朝上的点数总和为s的概率是多少？
（2）给一个数组和滑动窗口大小，求滑动窗口内的最大值是多少？


很幸运地遇到了和我做的方向非常match的组，boss也很有魅力，极速面试，菜鸡能够过面试很幸运很幸运，不出意外就上岸了吧，给大家分享一下我的面经，可能有些不全，回想起多少写多少


【商汤1面】

1. CornerNet介绍，CornerPooling是怎么做的，怎么解决cornernet检测物体合并为一个框的问题
2. 介绍Mimic知识蒸馏是怎么做的
3. MobileNet 介绍
4. 普通卷积、DW PW卷积计算量推导
5. MobileNet V2中的Residual结构最先是哪个网络提出来的
编程：
1. 之子形打印二叉树
2. MxN的方格中有多少个正方形、多少个矩形、有多少种不同面积矩形
【商汤2面】
1. 在人脸关键点和检测中的mimic是怎么做的？为什么不在logits输出上做？用l2 loss吗？
2. 人脸关键点使用pose做multitask为什么landmark会有提升？
3. 目标检测在工程中应用有没有遇到一些问题？检测类别冲突怎么办
4. 对机器学习了解多吗
5. 现有两个特征向量，怎么分析他们的相似度？
6. 有没有什么数学方法能够去除特征矩阵中的噪声？
编程：
1. 判断二叉树是否包含另一二叉树
2. 有序数组合并
【商汤3面-leader面】
主要与大boss聊自己的未来规划、对某个大方向做一些自己的分析
1. 介绍你在xx项目中的工作
2. 项目中你用做过SDK和安卓开发，是在这个项目中学的吗？
3. 你认为目前video和知识蒸馏这两个方向的挑战和可以改进的地方在哪
4. RNN为什么long-term dependency做不好
5. 你用了Memory Network，有提升吗
6. 你觉得网络模型和硬件平台是什么关系
7. 未来有什么打算，我带的两个组你想去哪个
8. 更想做出一个实用的产品还是做研究
【HR面】
主要介绍了公司的一些情况、福利，询问手中的offer情况，聊天______________

#面试经验# 商汤科技/旷视科技/拼多多/360/海康威视/BIGO
方向：ML/DL/CV

- 普通卷积、DW PW卷积计算量推导
- CornerNet介绍，CornerPooling是怎么做的
- MobileNet V2中的Residual结构最先是哪个网络提出来的
- GBDT中的CART回归树每个叶子节点的输出值是什么
- L1，L2的区别，L2为什么可以减轻过拟合
- 两个卷积核大小为（3,3），步长为（2，2）的卷积层堆叠，上层感受野大小是？
- 算法题，如何判断一个点在一个凸多边形里。
- 算法题，求两个链表的第一个公共节点
- 算法题：random_shuffle的实现
- 数学题，已知a,b都服从均值为0，方差为1的正态分布，求max(a,b)的期望
- 编程题：有序数组合并
- 编程题：2个有序链表的合并到多个有序链表的合并

#面试经验# 百度/网易/小米/商汤/作业帮/寒武纪/科大讯飞
方向：ML/DL/NLP/CV

- LR怎么加入非线性？
- yolov3中的anchor怎么生成的
- 梯度消失与梯度爆炸原因？解决方案
- Transformer/GPT/BERT 的原理讲解
- CenterNet具体是如何工作的，介绍一下其损失函数
- BN层怎么具体实现的(问的很具体，举例子说明)
- 各种激活函数介绍一下，优缺点及适用场景
- 怎么判断一个字符串是否是日期
- 过拟合、欠拟合怎么判断，解决
- SVM为什么叫支持向量机、损失函数是什么、核函数
- xgboost，每个叶子节点的值是怎么确定的？
- 编程题：青蛙跳台阶、变态青蛙跳台阶

#面试经验# 百度/字节跳动/小米/海康威视/猿辅导/BIGO
方向：ML/DL/CVNLP

- 解释一下菱形继承
- LSTM减弱梯度消失的原理
- 设计一个在CNN卷积核上做dropout的方式
- map的底层是用什么实现的，查询时间复杂度，插入和删除呢
- L1为什么能稀疏矩阵  L2为什么不能，L2为什么能解决过拟合
- 算法题：二叉树中的最长路径
- 算法题：x的平方根
- 算法题：二分查找
- 算法题：最大堆的插入
- 算法题：带括号的加减乘除字符串运算
- 算法题：最长连续递增序列
- 算法题：最长不连续序列
- 算法题：无序数组构建一棵二叉排序树

1面(1h10min) - 电面
约定电面晚上8点半(阿里是加班到9、10点的节奏？）
自我介绍：
项目
主要是商汤无人车实习的项目，问我比baseline提升15个点，怎么来的。
从数据迭代、backbone、模型修改几个层面上说了下。
挑一两个有意思的优化说说，说了cascade、hdcnn的结构，为什么用这种结构。
项目中出现什么情况，怎么解决的？主要就是说小目标检测的解决方案。
对caffe源码熟悉程度。（我扯了扯源码的底层设计模式，数据流怎么流的，如何添加新层、cuda代码的细节）
开放题
给了一个情景，如何训练模型、调优。（题目很空，主要考察你对深度学习的理解）
根据需求（前向传播时间、模型大小），确定模型和基础网络，跑第一版模型。（举了个栗子）
判断模型是否出现过拟合的情况，来决定下一步的优化方向。
结果分析(confusionMatrix等)，分析问题，将论文中的方法套上去，如果没有自己创造。（又举了个栗子）
softmax、多个logistic的各自的优势？1、类别数爆炸，2、推了下softmax反向传播的公式，来对比两者的优劣。
算法(走流程题)
字符串判断是否是ipv4，c++。(可能是时间不多了，大佬想下班了)
体会：
全程大多都是我在说，没有太多互动。后来经过源神@邢源建议，还是要故意给面试官漏点马脚让他们来怼我们，然后再怼回去，并说明不这么做的原因，不然不好拿高评分。(卧槽，真的是套路深啊～)
2面(1h30min) - 杭州电面
项目
大佬貌似涉猎很广泛，对每一个领域都很熟悉，基本上简历中的很多细节，他都能找到点怼我。（聊了很久）
项目是从头怼到尾，主要考察对项目、深度学习的理解。
大佬对我的trickList很感兴趣，我猜想他现在做的工作和我的很相似。
Anchor大小、长宽比选取？我说了业界常用的方法(YOLO9000中的方法)，并提了一个更优的方法。
如何解决小目标：
为什么要深层、浅层featureMap concat？提了点细节和我踩的坑，需要数量级上的调整，不然深层的feature可能会被压制。
Cascade的思想? 说了下我的摸索的一个过程。改变样本分布，困难样本挖掘，能达到比较好的效果。
文字识别使用ctc loss的一些细节
开放题
设计一个情景，倾斜字体检测，问我有什么好的想法？（我觉得应该是他现在遇到的问题）
数据增强，加入形变扰动。
非end-to-end版本：分别训练检测和分类，举了之前做过的一个文字识别的项目的实现。
end-to-end版本：加入仿射变换学习因子，学习字体倾斜的角度和形变。
在商汤发论文了吗？
没有，正在攒，项目比较重，但有一些work和insight，讲了下思路。（大佬听的很认真，貌似被我的故事打动了[捂脸]）
为啥要换实习？日常吹水。

评价：大佬主动评价我对模型理解挺好的，工作做的挺深的，说等下一面吧。

体会：二面面试官说话很快，思维比较敏捷，觉得和这种人讨论问题很欢畅，如果一起工作会很赞。
以后面试说话语速应该快一些，让人觉得思维比较敏捷，这个可能会有加分项吧。
3面(1h) - 电面

项目&基础

大佬应该是搞backbone模型优化的，问了我怎么迭代基础网络的版本的，日常扯论文，自己的实验结果和理解。
前两个卷积层通道数不用很多，主要是提取边缘、颜色信息，少量的卷积核足矣。
skip connection有什么好处？推了下反向传播公式，根据链式法则，梯度可以直接作用于浅层网络。
初始学习率怎么设？这个我真的没有总结过，只是说一般使用0.01～0.1。
mobileNet、shufflenet的原理？说了下原理。
为什么mobileNet在理论上速度很快，工程上并没有特别大的提升？先说了卷积源码上的实现，两个超大矩阵相乘，可能是group操作，是一些零散的卷积操作，速度会慢。
大佬觉得不满意，说应该从内存上去考虑。申请空间？确实不太清楚。
问我看过哪些前沿的论文？说了说最近两个月的优质的论文。
扯到了tripleLoss，大佬问样本怎么选择？随机，然后就被大佬嫌弃了。装逼失败，这块确实没怎么深入研究。
为什么用multiLoss？多loss权重如何选？训练普通的模型使其收敛，打印反向传播梯度的大小，这表示该task的难度，以此作为loss的权重，然后我补充说了下可以搞一个动态的loss权重，根据一段时间窗口来决定loss的权重。
开放性问题
凸优化了解吗？牛顿法、SGD、最小二乘法，各自的优势。
凸优化其他东西呢？我说只有一些零散的知识点的记忆，纯数学，没有很系统的研究。(面试官貌似数学功底很好，只能认怂)。
感觉有点虚，我尝试着往我会的地方引[捂脸]。
工程上如何对卷积操作进行优化？答：傅立叶模拟卷积。大佬不满意，说那是cudnn早就实现的，还有什么优化吗？（确实不知道，甩锅给工程组）
样本不均衡怎么处理？一个batch类别均等采样，修改loss对不同样本的权重。
体会：
三面面试官懂得不少，不过最后还是过了，有时间凸优化还是要系统整理下。
4面(50min) - 交叉面
项目
大佬应该不是做深度学习的，应该是机器学习那块的。交流中能感觉出来对这块不是很熟。挑他不会的玩命说，至少让他看到我的工作量。
基础
SVM的KTT条件？说了说，说到SMO实在说不下去了。
GBDT和randomForest区别？原理角度，方差、偏差角度，过拟合角度，谈了谈之前打阿里天池的一些经验吧。
GBDT和xgboost区别？算法上工程上的优化，面试前专门看了，总结的不错，知乎，更多细节可以看看陈天奇的论文，我没看过[捂脸]，做机器学习的小伙伴最好看看。
算法题
求和接近于target的连续子数组。（lintcode上有类似的题）
最后说让后面应该还有个hr面。

#面试经验# 阿里巴巴/BIGO/虹软/海康威视/猿辅导

- lightgbm和xgboost区别
- c++的行指针、列指针
- 卷积底层的实现方式（如caffe里面的img2col）
- 推导逻辑回归的损失函数和梯度计算
- dropout在训练和测试时不同，怎么保证测试结果稳定
- 如何在n个数组中找出它的中位数（n个数组无法完全放在内存中）
- 一道CV检测相关的题目，问作业本上的算式，通过bounding box检测出来，判断某个算式是在第几行第几列。
- 编程题：给你两个数，比如（7，10），有三种操作 +=3, += 7, +=9 （大概是这样）给出从7算到10最少的操作次数。
- 编程题：俄罗斯套娃信封问题
- 编程题：搜寻矩阵中的连通域个数

#面试经验# 腾讯/字节跳动/京东/拼多多/美团/寒武纪大华/作业帮
方向：ML/DL/CV/NLP

- LSTM与RNN的区别
- 得到AUC的两种计算方法
- XGBoost 和 GBDT的区别
- 树的分裂方式（id3,gini,gdbt,xgboost）
- XGBoost的损失函数是什么，节点划分准则是什么；
- 编程题： 给定两个队列，实现一个栈的功能；
- 编程题： 给定二叉树的前序和中序序列，重构二叉树；
- 编程题： 寻找数组的最短连续子数组的长度，使得子数组的和大于等于t。
- 给定一个大小为n*3的木板，问用大小为1*3的木板进行填充，有多少种填充方法；（斐波那契数列，动态规划）
- 求递增数组的最长子序列长度，要求子序列满足斐波那契数列；（leetcode原题，动态规划）



#面试经验# 腾讯/百度/京东/网易/商汤/美团/猿辅导
方向：ML/DL/推荐/CV/NLP

- ID3 C4.5 CART的区别
- Python is 和 ==的区别
- 手推 SVM, GBDT, XGBoost
- CRF 怎么训练的（传统+深度学习）
- Transformer 介绍，要做到精通内部实现
- PyTorch 多gpu训练机制的原理，优化器以及网络参数保存机制
- 编程题：不用库函数的情况下实现 split 函数
- 编程题：输入一个list， 输出list，要求奇数在左，偶数在右
- 编程题：输入一个字符串，返回不包含重复字符的subset 的最大长度
- 编程题：找到两个链表的公共节点
- 算法题：判断五子棋输赢，不用考虑复杂度 
- 算法题：搜寻矩阵中的连通域个数。


#面试经验# 腾讯/微信/拼多多/小米/依图/中兴有赞
方向：ML/DL/CV/NLP/RL

- BLSTM 和 LSTM 区别
- L1 正则化为什么能使特征稀疏？
- Stacking原理，还有怎么调优？
- DQN 损失函数是什么？
- 为什么逻辑回归要用交叉熵损失函数？
- XGBoost怎么调参？用了多少棵树？
- Dropout为什么能防止过拟合？具体实现
- 介绍 anchor-based和anchor-free两者的优缺点
- 各种决策树模型的优劣（从最简单的ID3到最后的LGB）
- 归并排序的时间复杂度，空间复杂度，归并排序的思想是什么。
- 编程题：反转链表
- 编程题：平衡二叉树
- 数学题：抛一枚硬币，第一次出现正面的期望
- 数学题：抛一枚硬币，连续两次出现正面的期望



#面试经验# 小米/美团/拼多多/寒武纪/小红书/招银网络
方向：ML/DL/CV/NLP

- 介绍 RNN LSTM 和 GRU
- 写出 word2vec 的 loss函数
- 写出 YOLOv3 的损失函数
- 什么是平衡二叉树以及红黑树
- 损失函数正则项的本质是什么? 
- Tensorflow的动态图和静态图有什么区别
- GN，BN，LN，IN 它们的共性和特性
- YOLOV1~V3系列介绍，以及每一版的改进，优缺点介绍
- 介绍金字塔池化，ASPP，深度可分，带孔卷积
- 为什么BN有泛化能力的改善. 什么场景用什么normalization方法，效果如何.
- 代码题：手撕堆排序
- 代码题：最小生成树算法
- 算法题：手撕 NMS


#面试经验# 快手/大疆/商汤/海康/OPPO/依图/BIGO/有赞
方向：ML/DL/CV

- 介绍 RANSAC
- 介绍一阶二阶边缘检测算子一阶二阶边缘检测算子
- 介绍 Bundle Adjustment
- LR介绍、LR对特征需要做什么特殊处理吗？类别特征、连续特征。LR介绍、LR对特征需要做什么特殊处理吗？类别特征、连续特征。
- 对分布式了解吗，说一说spark，hadoop对分布式了解吗，说一说spark，hadoop
- 介绍几个排序算法，时间复杂度，排序稳定性
- 代码：单词反转、树的层次遍历、怎么找到第k大的数代码：单词反转、树的层次遍历、怎么找到第k大的数
- 编程题：中值滤波、直方图相似度计算。编程题：中值滤波、直方图相似度计算。
- 编程题：有一个长度为n的数组，元素都是[1, n]且无重复，这时随机删除一个元素，1）求删除元素，2）要求时间复杂度O(n)，空间O(1)，3）不能改变数组，4）如果删除两个元素，如何求？



#面试经验# 阿里/腾讯/美团/商汤/拼多多/小米/作业帮/小红书
方向：ML/DL/CV/NLP/搜索

- XGBoost 的默认深度
- 推一下LR的损失函数以及梯度传递
- CNN Maxpooling 怎么反向传播？
- Inception（V1-V4）网络结构以及优缺点
- 介绍深度语言模型：BERT、ELMO、Transformer-XL等
- 各种决策树模型的优劣（从最简单的ID3到最后的LGB）
- SVM 核函数哪些是高维空间维度已知，哪些是未知的？
- 目前NLP技术的发展瓶颈在哪里，NLP技术落地有哪些困难，为什么？
- 编程题：写一个二叉树从根结点出发找最长路径
- 编程题：用 PyTorch写一下大致的train val的流程
- 编程题：给你三个题，选一个实现（knn kmeans 随机游走）


#面试题# 华为/旷视/图森未来/小米/360/搜狗
方向：ML/DL/CV/NLP/推荐

- 线程，进程区别，python的线程和进程
- ohem，到底比focal loss差再哪里了
- 介绍一下 attention机制，transfomer机制
- bn训练，测试区别，bn如何在inference是加速
- LSTM 详细结构与RNN相比如何解决梯度消失与爆炸
- 概率题：一件事件成功的概率是p，连续多次独立实验直到连续成功n次，求需要进行的实验次数期望。
- 编程题：一道单链表反转，一道最大公共子序列，一道求根号
- 编程题：一个很长的字符串序列长为N，里面有n种字符，比如英文序列由26个字符组成，选定m<=n种字符，在这个字符串序列中找一个连续子串需要包含m种字符，求满足要求的最小连续字串长度

面试题 阿里巴巴/华为/字节跳动/小米/猿辅导/寒武纪
方向：ML/DL/CV/NLP

- 介绍常见的边缘检测算法
- Transformer的结构是什么样的？
- Vector 底层怎么进行内存扩容的？
- 3×3 卷积核 与 5×5 卷积核相比的优点
- Transformer Decoder端的输入具体是什么？
- 程序的地址保存的是虚拟地址还是物理地址？
- Transformer是如何训练的？测试阶段如何进行测试呢？
- 介绍 MTCNN网络，有哪些层，卷积核大小和数量对模型的影响
- 输入图像灰度值对模型的影响，为什么要把0-255转化成0-1？
- 编程题：找出来数组中每个元素后边第一个比它大的值
- 编程题：打印出根节点到叶子节点的最长路径
- 编程题：给你一个二叉树，从上往下看，然后左往右顺序输出你能看到节点，同一个竖直方向上上面的节点把下面的节点遮挡住了


面试题 阿里巴巴/小米/OPPO/明略科技/招银网络

- 介绍SVM，其中的软间隔是什么意思？
- 使用线性回归的时候什么时候会需要用L2？
- Python中 List 函数的底层代码怎么实现的？
- 神经网络如果没有激活函数还能解决线性不可分问题吗？
- 如果F1已经趋于平稳，如何在保持F1稳定的前提下提高precision，降低recall；
- XGBoost 怎么解决过拟合？怎么剪枝？怎么选择特征？怎么处理缺失值？
- 卷积操作是线性的吗？CNN是线性的吗？为什么？（激活函数）常用的激活函数？
- 编程题：求一个整数开根号
- 编程题：二叉树了解吗？后序遍历是什么顺序？写一下代码。
- 编程题：python手写：给定一个字符串str，找出字符串中第M个只出现N次的字符，不存在则返回False



#面试题# 百度/京东/小米/依图/VIVO/58同城
方向：ML/DL/CV/NLP

- 解释几何间隔和函数间隔
- Dropout 前向和反向的处理
- BERT 的attention和普通的attention的区别
- LR 为什么不用 MSE，SVM 为什么用hinge不用logloss
- 公式及讲解soft attention，hard attention，multi head attention
- 描述决策树，如何选特征，怎么划分，怎么剪枝，介绍信息增益
- K-Means 聚类这种方法一定会收敛嘛？如果不收敛，怎么办？
- SVM 的目标函数，为什么能用拉格朗日乘子法讲原始最优化问题转化为极大极小问题，数学原理是什么
- 编程题：大数相加减
- 编程题：求一个字符串的所有子序列(字符串如果有重复字符，只取一次子序列)


#面试经验# 腾讯/百度/小米/寒武纪/科大讯飞/作业帮
方向：ML/DL/CV/NLP/RL

- AUC和ROC含义
- 完全二叉树的概念
- 浅copy和深copy的区别
- 朴素贝叶斯与贝叶斯有什么区别？
- 列表的排序算法，归并排序的原理
- SVM 为什么变成对偶问题来求解？
- LSTM里面有哪些门，为什么用这些门？
- 缺失值如何处理，什么情况下均值、众数，什么情况下丢弃特征。
- 诸如ID类的特征如何处理，编码方式one-hot还是其他的，高维时？什么样才算高维，有没有界定？
- 聚类的算法有哪些？评价方法？优化算法？
- 编程题：给出前序遍历和中序遍历，重建二叉树
- 编程题：两个字符串求最长公共子序列，青蛙跳台阶问题

面试经验 商汤/海康威视/大华/BIGO/奥比中光/Keep

方向：ML/DL/CV/NLP/RL

- 常用颜色空间
- 决策树分支的原理
- 手写灰度直方图代码
- RPN怎么计算 box 的实际坐标
- 介绍常见的损失函数（应用场景）
- offerpolicy 和 onpolicy 的区别
- 介绍常见的 Anchor free 目标检测算法
- Focal Loss是如何进行难分样本挖掘的？
- 为什么随机森林的树比 GBDT 的深一点？
- 逻辑回归的目标函数(损失函数)是凸函数吗？
- 算法题：编程实现目标检测中的 IoU 计算

#面试经验# 百度/VIVO/依图/华为新浪微博/58同城

方向：ML/DL/CV/NLP

- LSTM 的改进点有哪些？
- CNN 的感受野受什么影响
- transformer和RNN的区别
- LR 为什么用sigmoid函数？
- CNN 如何保持平移方向不变性
- 怎么解决样本不均衡（重点考核损失函数优化）
- 介绍softmax和分层softmax，还有负采样？怎么负采样？
- 算法题：线段区间拼接问题，类似leetcode-56。
- 算法题：给一个固定长度的窗口和一些标记区间，输出包含最多区间的窗口
- 数学题：有一个一次只能读取buffer，一个不知道有多少元素的链表。现在想基于这个链表与这个buffer实现一个获取链表中随机元素的函数。
- 概率题：有n个人，m个坏人。每次检查一个人无论是不是坏人都会导致这个人死亡。那么查到第一个坏人的死掉好人的期望是多少。

#面试经验# 百度/京东/小米/美团/海康威视/招银网络

方向：ML/DL/CV/NLP

- 介绍 ROC 和 AUC
- HMM 和 CRF的区别
- 介绍 RNN 的反向传播
- XGBoost 如何处理缺失数据？
- 写一下 LR 和 SVM 的损失函数
- 正负样本不均衡时的解决方案
- 知道哪些降维的方法，具体讲讲
- 线性模型和非线性模型都有哪些？
- 手写AUC的计算（小矩形积分得到总面积即可）
- 如果分类的数据图像每一类只有几张，你会用什么方法？
- 编程题：哈希表求次数输出
- 编程题：求数组中第k大的数
- 编程题：判断链表中是否有环
- 编程题：求出链表中环的位置
