



1面(1h10min) - 电面
约定电面晚上8点半(阿里是加班到9、10点的节奏？）
自我介绍：
项目
主要是商汤无人车实习的项目，问我比baseline提升15个点，怎么来的。
从数据迭代、backbone、模型修改几个层面上说了下。
挑一两个有意思的优化说说，说了cascade、hdcnn的结构，为什么用这种结构。
项目中出现什么情况，怎么解决的？主要就是说小目标检测的解决方案。
对caffe源码熟悉程度。（我扯了扯源码的底层设计模式，数据流怎么流的，如何添加新层、cuda代码的细节）
开放题
给了一个情景，如何训练模型、调优。（题目很空，主要考察你对深度学习的理解）
根据需求（前向传播时间、模型大小），确定模型和基础网络，跑第一版模型。（举了个栗子）
判断模型是否出现过拟合的情况，来决定下一步的优化方向。
结果分析(confusionMatrix等)，分析问题，将论文中的方法套上去，如果没有自己创造。（又举了个栗子）
softmax、多个logistic的各自的优势？1、类别数爆炸，2、推了下softmax反向传播的公式，来对比两者的优劣。
算法(走流程题)
字符串判断是否是ipv4，c++。(可能是时间不多了，大佬想下班了)
体会：
全程大多都是我在说，没有太多互动。后来经过源神@邢源建议，还是要故意给面试官漏点马脚让他们来怼我们，然后再怼回去，并说明不这么做的原因，不然不好拿高评分。(卧槽，真的是套路深啊～)
2面(1h30min) - 杭州电面
项目
大佬貌似涉猎很广泛，对每一个领域都很熟悉，基本上简历中的很多细节，他都能找到点怼我。（聊了很久）
项目是从头怼到尾，主要考察对项目、深度学习的理解。
大佬对我的trickList很感兴趣，我猜想他现在做的工作和我的很相似。
Anchor大小、长宽比选取？我说了业界常用的方法(YOLO9000中的方法)，并提了一个更优的方法。
如何解决小目标：
为什么要深层、浅层featureMap concat？提了点细节和我踩的坑，需要数量级上的调整，不然深层的feature可能会被压制。
Cascade的思想? 说了下我的摸索的一个过程。改变样本分布，困难样本挖掘，能达到比较好的效果。
文字识别使用ctc loss的一些细节
开放题
设计一个情景，倾斜字体检测，问我有什么好的想法？（我觉得应该是他现在遇到的问题）
数据增强，加入形变扰动。
非end-to-end版本：分别训练检测和分类，举了之前做过的一个文字识别的项目的实现。
end-to-end版本：加入仿射变换学习因子，学习字体倾斜的角度和形变。
在商汤发论文了吗？
没有，正在攒，项目比较重，但有一些work和insight，讲了下思路。（大佬听的很认真，貌似被我的故事打动了[捂脸]）
为啥要换实习？日常吹水。

评价：大佬主动评价我对模型理解挺好的，工作做的挺深的，说等下一面吧。

体会：二面面试官说话很快，思维比较敏捷，觉得和这种人讨论问题很欢畅，如果一起工作会很赞。
以后面试说话语速应该快一些，让人觉得思维比较敏捷，这个可能会有加分项吧。
3面(1h) - 电面

项目&基础
大佬应该是搞backbone模型优化的，问了我怎么迭代基础网络的版本的，日常扯论文，自己的实验结果和理解。
前两个卷积层通道数不用很多，主要是提取边缘、颜色信息，少量的卷积核足矣。
skip connection有什么好处？推了下反向传播公式，根据链式法则，梯度可以直接作用于浅层网络。
初始学习率怎么设？这个我真的没有总结过，只是说一般使用0.01～0.1。
mobileNet、shufflenet的原理？说了下原理。
为什么mobileNet在理论上速度很快，工程上并没有特别大的提升？先说了卷积源码上的实现，两个超大矩阵相乘，可能是group操作，是一些零散的卷积操作，速度会慢。
大佬觉得不满意，说应该从内存上去考虑。申请空间？确实不太清楚。
。






























